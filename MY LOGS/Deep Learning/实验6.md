# <center>实验六      基于 Pytorch 实现 SRGAN 图片降噪</center>
#### <center>小组成员： 岳思源    **120L021112**     </center>



# 1 项目说明：
## 1.1 选题说明：
超分辨率降噪是一种图像修复方法，通过将低分辨率和带噪声的图像转换为高分辨率和无噪声的图像。这种方法在计算机视觉和图像处理中具有重要的应用，能够帮助我们从劣质的图像中提取更清晰的细节信息。

超分辨率降噪通常分为两个步骤：超分辨率重建和噪声去除。超分辨率重建通过将低分辨率图像转换为高分辨率图像来提高图像的质量。最近，深度学习技术如 SRCNN、VDSR、SRGAN 等已经在该领域中取得了很大的成功。噪声去除通过去除图像中的噪声来提高图像质量。噪声去除方法有许多技术，包括基于小波的方法、基于总变分的方法和深度学习方法等。

我的选题就是基于 `pytorch` 实现 *SRGAN* 进行图片的超分辨率降噪。
## 1.2 SRGAN
**SRGAN** 是一种超分辨率生成对抗网络，全称为 `Super-Resolution Generative Adversarial Networks`。它采用生成对抗网络的结构，通过学习对高分辨率图像进行*超分辨率重构*。**SRGAN** 通过引入残差块和跳跃连接来优化生成器的训练，并通过对抗框架来促进生成器和判别器之间的竞争，以获得更好的生成结果。相较于传统的双三次插值以及 Nearest Neighbor interpolation，SRGAN 有效地提高了图像的质量和分辨率，因此在图像重建和图像超分辨率的任务中具有广泛应用。
## 1.3 数据集描述
训练集和验证集：
>COCO2014 是一个大型的图像识别、分割和描述数据集，数据集包含超过 330, 000 张图像和超过 2.5 万个类别的物体标注。每张图像都有超过 5 个人工注释，其中包括对象边界框、分割掩模以及图像描述。此外，COCO2014 数据集还包括用于评估算法性能的大型集合验证集和测试集。
>该实验训练集和测试集分别选择 COCO 2014 划分好的 `train2014` 和 `val2014`。
>下载链接：[train2014](http://images.cocodataset.org/zips/train2014.zip) [val2014](http://images.cocodataset.org/zips/val2014.zip)

测试集：
>测试集选用 CIFAR-10 的测试集
>CIFAR-10 是一个经典的图像分类数据集，由 10 个类别的 60000 张彩色图像组成，其中训练集包含 50000 张图像，*测试集包含 10000 张图像*。每个图像的大小为*32x32*像素，图像中包含的类别有飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。
>数据量较小


### 数据预处理过程：
```python
randomcrop = transforms.RandomCrop(96)  #原始图片的大小不一，需要截成同样大小，这里用的是随机裁剪，也可以用其他裁剪方式

class MyDataset(Dataset):
    def __init__(self, path, transform, sigma=30, ex=1):
        self.transform = transform 
        self.sigma = sigma
        for _, _, files in os.walk(path):
            self.imgs = [path + file for file in files if Image.open(path + file).size >= (96,96)] * ex
            #仅读取大小大于或等于96*96的图片，ex是数据增广系数，即把同一张图片复制多份以达到扩充数据量的目的
        np.random.shuffle(self.imgs) #打乱顺序

    def __getitem__(self, index):
        tempImg = self.imgs[index]
        tempImg = Image.open(tempImg).convert('RGB')
        Img = np.array(self.transform(tempImg))/255  #像素归一化至[0,1]
        nImg = addGaussNoise(Img, self.sigma) 
        Img = torch.tensor(Img.transpose(2,0,1))
        nImg = torch.tensor(nImg.transpose(2,0,1))
        return Img, nImg

    def __len__(self):
        return len(self.imgs)
```

# 2. 方案设计
>该论文 $^{[1]}$ 提出了一个超分辨率生成对抗网络（SRGAN），采用了一个深度残差网络（ResNet），该网络具有跳过连接和发散 MSE 作为唯一的优化目标。与以前的工作不同，使用 VGG 网络的高级特征图[49，33，5]与一个 discriminator 相结合，定义一种新的感知损失，该鉴别器鼓励在感知上难以与 HR 参考图像区分开来的解决方案。

## 2 .1 卷积神经网络设计
1. 批量归一化层
	
	论文提到研究表明，更深的网络架构可能难以训练，但有可能大幅提高网络的准确性，因为它们允许对非常复杂的映射进行建模[49，51]。为了有效地训练这些更深层次的网络架构，通常使用批量归一化[32]来抵消内部协变量偏移。
```python
self.layer1 = nn.Sequential(nn.Conv2d(inC, outC, kernel_size=3, stride=1, padding=1, bias=False), 
                                    nn.BatchNorm2d(outC), #批量归一化层
                                    nn.PReLU())

```
2. 残差块
```python
	class ResBlock(nn.Module):
    def __init__(self, inC, outC):
        super(ResBlock, self).__init__()
        self.layer1 = nn.Sequential(nn.Conv2d(inC, outC, kernel_size=3, stride=1, padding=1, bias=False), 
                                    nn.BatchNorm2d(outC), #批量归一化层
                                    nn.PReLU())

        self.layer2 = nn.Sequential(nn.Conv2d(outC, outC, kernel_size=3, stride=1, padding=1, bias=False), 
                                    nn.BatchNorm2d(outC))

    def forward(self, x):
        resudial = x

        out = self.layer1(x)
        out = self.layer2(out)
        out = out + resudial

        return out
```

3. 使用跳接（skip-connection）

## 2.2 Loss Function

SRGAN 论文提出的损失函数有两个部分： 对抗损失（Adversarial Loss）和内容损失（Content Loss）。

对抗损失使用一个被训练以区分超分辨率图像和原始现实图像的**判别器**网络将网络的结果推导至自然图像流形，由此降低数据维度。SRGAN 使用了一种以感知相似性驱动的内容损失，而不是像素的相似性。

对抗损失的代价函数是基于判别器输出的概率：
 $$l^{SR}_{G_{en}} = \sum_{n=1}^{N} -log D_{\theta_D}(G_{\theta_G}(I^LR)) $$
其中 $D_{\theta_d}(G_{\theta_d)}(I^{LR})$ 表示的是重构图像是自然的高分辨率图像的概率。$D_{\theta D}()$ 是一个分类网络。为了更好的梯度表现，选择最小化 $-logD_{\theta_D}(G_{\theta_G}(I^LR))$ 而非 $log[1-D_{\theta_D}(G_{\theta_G}(I^LR))]$。

判别器的代价函数:
$$\min_{\theta_G}\max_{\theta_D} E_{I^{HR}\sim p_{train}(I^{HR})}[log D_{\theta_D}(I^{HR})]+E_{I^{HR}\sim p_{G}(I^{HR})}[log[1-D_{\theta_D}(G_{\theta_G}(I^LR))]$$
 其中，$I^{SR}$ 表示 SRGAN 网络重建的高分辨率图像, $I^{HR}$ 是原本的高分辨率图像，$I^{LR}$  是高分辨率图像对应的低分辨率图像。

内容的代价函数除了 MSE 像素空间最小均方误差外，又包含了一个基于特征空间的最小均方误差，该特征是利用 VGG 网络提取的图像高层次特征:
$l_X^{SR}=l^{SR}_{VGG/i.j} = 1/(W_{i, j}H_{i, j})\sum_{x=1}^{W_{i, j}}\sum_{y=1}^{H_{i,j}}(\phi_{i,j}(G_{\theta_G}(I^{LR}))_{xy})^2$

将上述两种损失结合起来，就是感知损失函数 (Perceptual loss function):
![[Pasted image 20230618193108.png]]

## 2.3 网络结构
这是 GAN 中的生成器和判别器的网络结构，生成器由残差网络组成，并与批量归一化（Batch Normalization）层相结合，其作用是生成尽可能逼真的图像。由生成器生成的图像将被放入判别器，它将判别该图像是生成的假高分辨率图像还是真正的高分辨率图像。
![[Pasted image 20230618193213.png]]

# 3 实验过程与结果
设置残差块数量为 5，Generator 学习率为 0.0001 , Discriminator 学习率设置为 0.001，并使用 Early Stopping 来防止过拟合
最终训练模型在测试集平均 PSNR 为 19.3715，平均 SSIM 为 0.8237 的模型
我们对训练过的模型使用该图像进行检测：
原图像：
![[10723-1P5200S644560.png]]
生成噪声后：
![[noiseimg_011_SRF_4_HR 1.png]]
使用训练好的 SRGAN 模型进行去噪：
![[set5_gan_test 1.png]]
确实有非常不错的效果。
# 4. 参考文献
1. [C. Ledig et al., "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network," 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 105-114, doi: 10.1109/CVPR.2017.19.](https://arxiv.org/pdf/1609.04802.pdf)
2. [(37条消息) 深度学习_GAN_SRGAN论文详解及优化_srgan优化_WeThinkIn的博客-CSDN博客](https://blog.csdn.net/Rocky6688/article/details/104369905)
3. https://zhuanlan.zhihu.com/p/618079137 
