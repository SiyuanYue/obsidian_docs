# <center>实验五               生成式对抗网络</center>
#### <center>岳思源      **120L021112**</center>

# 1. 实验环境
`CUDA 12.1` ,  `pytorch-cuda=11.8` , `python 3.8`, `RTX2060`
# 2. 生成式对抗网络实现
## 2.1  生成式对抗网络介绍：
### 2.1.1 GAN
生成对抗网络（Generative Adversarial Networks，*GAN*）是通过对抗训练的方式来使得生成网络产生的样本服从真实数据分布．在生成对抗网络中，有两个网络进行对抗训练．*一个是判别网络*，目标是尽量准确地判断一个样本是来自于真实数据还是由生成网络产生；*另一个是生成网络*，目标是尽量生成判别网络无法区分来源的样本．这两个目标相反的网络不断地进行交替训练．当最后收敛时，如果判别网络再也无法判断出一个样本的来源，那么也就等价于生成网络可以生成符合真实数据分布的样本．生成对抗网络的流程图如图所示.
![[Pasted image 20230601205328.png]]
**判别网络**（Discriminator Network）𝐷(𝒙; 𝜙) 的目标是区分出一个样本 𝒙 是来自于真实分布 𝑝𝑟(𝒙) 还是来自于生成模型 𝑝𝜃(𝒙)，因此判别网络实际上是一个二分类的分类器。
判别网络的目标函数为最小化交叉熵，即
$min_𝜙 −(𝔼_𝒙[y log p(y = 1|x) + (1 − 𝑦) log p(y = 0|x)]).$
分布 𝑝(𝒙) 是由分布 𝑝𝑟(𝒙) 和分布 𝑝𝜃(𝒙) 等比例混合而成，即 $𝑝(𝒙) =1/2 (𝑝𝑟(𝒙) + 𝑝𝜃(𝒙))$，则上式等价于
$max_𝜙𝔼𝒙∼𝑝𝑟(𝒙)[ log 𝐷(𝒙; 𝜙)] + 𝔼x′∼𝑝𝜃(x′)[ log (1 − 𝐷(𝒙′; 𝜙))]$
= $max_𝜙𝔼𝒙∼𝑝𝑟(𝒙)[ log 𝐷(𝒙; 𝜙)] + 𝔼𝒛∼𝑝(𝒛)[ log (1 − 𝐷(𝐺(𝒛; 𝜃); 𝜙))]$
**生成网络**（Generator Network）的目标刚好和判别网络相反，即让判别网
络将自己生成的样本判别为真实样本。$max_𝜃(𝔼𝒛∼𝑝(𝒛)[ log 𝐷(𝐺(𝒛; 𝜃); 𝜙)])$
```python
class GAN_Generator(torch.nn.Module):  # 继承 torch 的 Module    def __init__(self, in_features: int, out_features: int):  
        super(GAN_Generator, self).__init__()  # 调用父类构造函数，继承 __init__ 功能  
        self.generator = torch.nn.Sequential(  
            torch.nn.Linear(in_features, 512),  # 输入层  
            torch.nn.ReLU(),  
            torch.nn.Linear(512, 256),  # 隐藏层  
            torch.nn.ReLU(),  
            torch.nn.Linear(256, out_features),  # 输出层  
        )  
  
    def forward(self, x_in):  
        return self.generator(x_in)  
  
  
class GAN_Discriminator(torch.nn.Module):  # 继承 torch 的 Module    def __init__(self, in_features: int, out_features: int):  
        super(GAN_Discriminator, self).__init__()  # 调用父类构造函数，继承 __init__ 功能  
        self.discriminator = torch.nn.Sequential(  
            torch.nn.Linear(in_features, 256),  # 输入层  
            torch.nn.ReLU(),  
            torch.nn.Linear(256, 256),  # 隐藏层  
            torch.nn.ReLU(),  
            torch.nn.Linear(256, out_features),  # 输出层  
            torch.nn.Sigmoid()  
        )  
    def forward(self, x_in):  
        return self.discriminator(x_in)
```
### 2.1.2 WGAN
WGAN 与原始 GAN 的区别在于：
- WGAN 的代价函数中并不存在 log（不使用交叉熵，而使用 Wasserstein 距离来衡量损失）。 
- 对于判别器 D，由于 WGAN 的目标在于测量生成数据分布与真实数据分布之间的距离（Wasserstein 距离），而非原始 GAN 的是与否的二分类问题，所以去掉了最后输出层的 Sigmoid 激活函数。 
- 在更新权重的时候，我们需要加上权值裁剪使得网络参数能够保持在一定的范围内，从而满足 Lipschitz 条件。 
- 将 Adam 等梯度下降方法改为使用 *RMSProp* 方法，这个是 WGAN 的作者经过大量实验得出的结论，使用 Adam 等方法会导致训练的不稳定，而 RMSProp 可以有效避免不稳定问题的发生，在实验中也是如此，*RMSProp 效果明显由于 Adam*

```python
self.discriminator = torch.nn.Sequential(  
    torch.nn.Linear(in_features, 256),   
    torch.nn.ReLU(),  
    torch.nn.Linear(256, 256),  
    torch.nn.ReLU(),  
    torch.nn.Linear(256, out_features),  
    # 去掉了sigmoid，近似拟合Wasserstein距离  
)
```
### 2.1.3 WGAN_GP
WGAN-GP 与 WGAN 的区别在于使用*梯度惩罚*（gradient penalty）来替代权值裁剪, 并使得 adam 优化器更加稳定。

## 2.2 实验结果对比
###  对比 GAN、WGAN、WGAN-GP（稳定性、性能）
1. 同为 adam 优化器：

GAN: ![[Pasted image 20230601212659.png]]
WGAN:
![[Pasted image 20230601212825.png]]

WGAN_GP:
![[Pasted image 20230601212937.png]]
可以看出 `GAN` 和 `WGAN` 在 `ADAM` 优化器下都表现不佳。**WGAN_GP**在 Adam 优化器下拟合表现明显更好。
2. 同为 RMSprop:

GAN:
![[Pasted image 20230601213204.png]]
WGAN:
![[Pasted image 20230601213256.png]]
WGAN_GP:
![[Pasted image 20230601213506.png]]
首先可以看到三者在 **RMSprop**优化器下的拟合表现相比**Adam**都有相当明显的提升。GAN 和 WGAN 拟合出来的图像相似，区别不大，而 WGAN_GP 拟合出来的图像效果最好。

## 2.3 隐空间语义方向搜索
1. 性别：
 ![[frame0.png]]
![[frame1.png]]
由男->女
2. 人脸朝向：
![[frame2 1.png]]
由向右->向左
3. 年龄
![[frame3 1.png]]
4. 笑容
![[frame3.png]]


