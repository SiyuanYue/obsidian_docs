>许多教科书教授一系列的主题，每一个都非常详细。例如，Chris Bishop的优秀教科书 ([Bishop, 2006](https://zh.d2l.ai/chapter_references/zreferences.html#id10 "Bishop, C. M. (2006). Pattern recognition and machine learning. springer.")) ，对每个主题都教得很透彻，以至于要读到线性回归这一章需要大量的工作。虽然专家们喜欢这本书正是因为它的透彻性，但对初学者来说，这一特性限制了它作为介绍性文本的实用性。
>
>我们在开始时花了一些时间来教授基础的背景知识，如线性代数和概率，但我们希望你在思考更深奥的概率分布之前，**先体会一下训练模型的满足感**。

# 引言
> 我们试着用一台计算机和一个代码编辑器编写代码，如 [图1.1.1](https://zh.d2l.ai/chapter_introduction/index.html#fig-wake-word) 中所示。问题看似很难解决：麦克风每秒钟将收集大约 44000 个样本，每个样本都是声波振幅的测量值。而该测量值与唤醒词难以直接关联。那又该如何编写程序，令其输入麦克风采集到的原始音频片段, 输出是否{是, 否}（表示该片段是否包含唤醒词）的可靠预测呢？我们对编写这个程序毫无头绪，这就是需要机器学习的原因。
>总而言之，我们没有编写唤醒词识别器，而是编写了一个“学习”程序。如果我们用一个巨大的带标签的数据集，它很可能可以“学习”识别唤醒词。这种“通过用数据集来确定程序行为”的方法可以被看作_用数据编程_（programming with data）

# 机器学习关键组件
## 数据
>并不是所有的数据都可以用“固定长度”的向量表示。以图像数据为例，如果它们全部来自标准显微镜设备，那么“固定长度”是可取的；但是如果图像数据来自互联网，它们很难具有相同的分辨率或形状。这时，将图像裁剪成标准尺寸是一种方法，但这种办法很局限，有丢失信息的风险。此外，文本数据更不符合“固定长度”的要求。比如，对于亚马逊等电子商务网站上的客户评论，有些文本数据很简短（比如“好极了”），有些则长篇大论。与传统机器学习方法相比，深度学习的一个主要优势是可以处理不同长度的数据。
## 模型
> 深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为_深度学习_（deep learning）。在讨论深度模型的过程中，本书也将提及一些传统方法。
## 目标函数/损失函数
> 通常，损失函数是根据模型参数定义的，并取决于数据集。在一个数据集上，我们可以通过最小化总损失来学习模型参数的最佳值。该数据集由一些为训练而收集的样本组成，称为_训练数据集_（training dataset，或称为_训练集_（training set））。然而，在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的性能，这里的“新数据集”通常称为_测试数据集_（test dataset，或称为_测试集_（test set））。

## 算法
> 接下来就需要一种算法，它能够搜索出最佳参数，以最小化损失函数。深度学习中，大多流行的优化算法通常基于一种基本方法–_梯度下降_（gradient descent）。

# 各种机器学习问题
## 监督学习
1. 回归
2. 分类
3. 标注：
>学习预测不相互排斥的类别的问题称为_多标签分类_（multi-label classification）。举个例子，人们在技术博客上贴的标签，比如“机器学习”“技术”“小工具”“编程语言”“Linux”“云计算”“AWS”。一篇典型的文章可能会用 5～10 个标签，因为这些概念是相互关联的。关于“云计算”的帖子可能会提到“AWS”，而关于“机器学习”的帖子也可能涉及“编程语言”

4. 推荐系统
5. 序列问题    
*HMM?*
**标记和解析**
**自动语音识别**
**文本到语音**
**机器翻译**  : 在语音识别中，输入和输出的出现顺序基本相同。而在机器翻译中，颠倒输入和输出的顺序非常重要。换句话说，虽然我们仍将一个序列转换成另一个序列，但是输入和输出的数量以及相应序列的顺序大都不会相同。
## 无监督学习：
-   _聚类_（clustering）问题：没有标签的情况下，我们是否能给数据分类呢？比如，给定一组照片，我们能把它们分成风景照片、狗、婴儿、猫和山峰的照片吗？同样，给定一组用户的网页浏览记录，我们能否将具有相似行为的用户聚类呢？
    
-   _主成分分析_（principal component analysis）问题：我们能否找到少量的参数来准确地捕捉数据的线性相关属性？比如，一个球的运动轨迹可以用球的速度、直径和质量来描述。再比如，裁缝们已经开发出了一小部分参数，这些参数相当准确地描述了人体的形状，以适应衣服的需要。另一个例子：在欧几里得空间中是否存在一种（任意结构的）对象的表示，使其符号属性能够很好地匹配?这可以用来描述实体及其关系，例如“罗马” − “意大利” + “法国” = “巴黎”。
    
-   _因果关系_（causality）和_概率图模型_（probabilistic graphical models）问题：我们能否描述观察到的许多数据的根本原因？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和工资的人口统计数据，我们能否简单地根据经验数据发现它们之间的关系？
    
-   _生成对抗性网络_（generative adversarial networks）：为我们提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域。

## 与环境互动
有人一直心存疑虑：机器学习的输入（数据）来自哪里？机器学习的输出又将去往何方？ 到目前为止，不管是监督学习还是无监督学习，我们都会预先获取大量数据，然后启动模型，不再与环境交互。 这里所有学习都是在算法与环境断开后进行的，被称为_离线学习_（offline learning）。 对于监督学习，从环境中收集数据的过程类似于 [图1.3.6](https://zh.d2l.ai/chapter_introduction/index.html#fig-data-collection)。

![../_images/data-collection.svg](https://zh.d2l.ai/_images/data-collection.svg)

这种简单的离线学习有它的魅力。 好的一面是，我们可以孤立地进行模式识别，而不必分心于其他问题。 但缺点是，解决的问题相当有限。 这时我们可能会期望人工智能不仅能够做出预测，而且能够与*真实环境互动*。 与预测不同，“与真实环境互动”实际上会影响环境。 这里的人工智能是“智能代理”，而不仅是“预测模型”。 因此，我们必须考虑到*它的行为可能会影响未来的观察结果*。
考虑“与真实环境互动”将打开一整套新的建模问题。以下只是几个例子。
-   环境还记得我们以前做过什么吗？
-   环境是否有助于我们建模？例如，用户将文本读入语音识别器。
-   环境是否想要打败模型？例如，一个对抗性的设置，如垃圾邮件过滤或玩游戏？
-   环境是否重要？
-   环境是否变化？例如，未来的数据是否总是与过去相似，还是随着时间的推移会发生变化？是自然变化还是响应我们的自动化工具而发生变化？

当训练和测试数据不同时，最后一个问题提出了**分布偏移**（distribution shift）的问题。接下来的内容将简要描述强化学习问题，这是一类明确考虑与环境交互的问题。
## 强化学习
强化学习问题中，智能体（agent）在一系列的时间步骤上与环境交互。在每个特定时间点，智能体从环境接收一些_观察_（observation），并且必须选择一个_动作_（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后智能体从环境中获得_奖励_（reward）。此后新一轮循环开始，智能体接收后续观察，并选择后续操作，依此类推。强化学习的过程在 [图1.3.7](https://zh.d2l.ai/chapter_introduction/index.html#fig-rl-environment) 中进行了说明。请注意，强化学习的目标是产生一个好的_策略_（policy）。强化学习智能体选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。

![../_images/rl-environment.svg](https://zh.d2l.ai/_images/rl-environment.svg)

强化学习问题中，智能体（agent）在一系列的时间步骤上与环境交互。在每个特定时间点，智能体从环境接收一些观察（observation），并且必须选择一个动作（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后智能体从环境中获得奖励（reward）。此后新一轮循环开始，智能体接收后续观察，并选择后续操作，依此类推。强化学习的过程在图 1.3.7 中进行了说明。请注意，强化学习的目标是产生一个好的策略（policy）。强化学习智能体选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。

>强化学习框架的通用性十分强大。例如，我们可以将任何监督学习问题转化为强化学习问题。假设我们有一个分类问题，可以创建一个强化学习智能体，每个分类对应一个“动作”。然后，我们可以创建一个环境，该环境给予智能体的奖励。这个奖励与原始监督学习问题的损失函数是一致的。

强化学习者必须处理_学分分配_（credit assignment）问题：决定哪些行为是值得奖励的，哪些行为是需要惩罚的。
当环境可被完全观察到时，强化学习问题被称为**马尔可夫决策过程**（markov decision process）。当状态不依赖于之前的操作时，我们称该问题为上下文赌博机（contextual bandit problem）。当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的多臂赌博机（multi-armed bandit problem）。

# 深度学习起源
_神经网络_（neural networks）的得名源于生物灵感。一个多世纪以来（追溯到 1873 年亚历山大·贝恩和 1890 年詹姆斯·谢林顿的模型），研究人员一直试图组装类似于相互作用的神经元网络的计算电路。随着时间的推移，对生物学的解释变得不再肤浅，但这个名字仍然存在。其核心是当今大多数网络中都可以找到的几个关键原则：
-   线性和非线性处理单元的交替，通常称为**层**（layers）；
-   使用链式规则（也称为**反向传播**（backpropagation））一次性调整网络中的全部参数。
# 发展

>随机存取存储器没有跟上数据增长的步伐。与此同时，算力的增长速度已经超过了现有数据的增长速度。这意味着统计模型需要提高内存效率（这通常是通过添加非线性来实现的），同时由于计算预算的增加，能够花费更多时间来优化这些参数。因此，机器学习和统计的关注点从（广义的）线性模型和核方法转移到了深度神经网络。这也造就了许多深度学习的中流砥柱，如多层感知机 ([McCulloch and Pitts, 1943]( https://zh.d2l.ai/chapter_references/zreferences.html#id106 "McCulloch, W. S., & Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5 (4), 115–133.")) 、卷积神经网络 ([LeCun _et al._, 1998]( https://zh.d2l.ai/chapter_references/zreferences.html#id90 "LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., & others. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86 (11), 2278–2324.")) 、长短期记忆网络 ([Graves and Schmidhuber, 2005]( https://zh.d2l.ai/chapter_references/zreferences.html#id51 "Graves, A., & Schmidhuber, J. (2005). Framewise phoneme classification with bidirectional lstm and other neural network architectures. Neural networks, 18 (5-6), 602–610.")) 和 Q 学习 ([Watkins and Dayan, 1992]( https://zh.d2l.ai/chapter_references/zreferences.html#id179 "Watkins, C. J., & Dayan, P. (1992). Q-learning. Machine learning, 8 (3-4), 279–292.")) ，在相对休眠了相当长一段时间之后，在过去十年中被“重新发现”。

>-   在许多情况下，单个 GPU 不足以处理可用于训练的大量数据。在过去的十年中，构建并行和分布式训练算法的能力有了显著提高。设计可伸缩算法的关键挑战之一是深度学习优化的主力——随机梯度下降，它依赖于相对较小的小批量数据来处理。同时，小批量限制了 GPU 的效率。因此，在 1024 个 GPU 上进行训练，例如每批 32 个图像的小批量大小相当于总计约 32000 个图像的小批量。最近的工作，首先是由 ([Li, 2017]( https://zh.d2l.ai/chapter_references/zreferences.html#id91 "Li, M. (2017). Scaling Distributed Machine Learning with System and Algorithm Co-design (Doctoral dissertation). PhD Thesis, CMU.")) 完成的，随后是 ([You _et al._, 2017]( https://zh.d2l.ai/chapter_references/zreferences.html#id192 "You, Y., Gitman, I., & Ginsburg, B. (2017). Large batch training of convolutional networks. arXiv preprint arXiv: 1708.03888.")) 和 ([Jia _et al._, 2018]( https://zh.d2l.ai/chapter_references/zreferences.html#id79 "Jia, X., Song, S., He, W., Wang, Y., Rong, H., Zhou, F., … others. (2018). Highly scalable deep learning training system with mixed-precision: training imagenet in four minutes. arXiv preprint arXiv: 1807.11205.")) ，将观察大小提高到 64000 个，将 ResNet-50 模型在 ImageNet 数据集上的训练时间减少到不到 7 分钟。作为比较——最初的训练时间是按天为单位的。
>深度学习框架在传播思想方面发挥了至关重要的作用。允许轻松建模的第一代框架包括 [Caffe](https://github.com/BVLC/caffe)、[Torch](https://github.com/torch) 和 [Theano](https://github.com/Theano/Theano)。许多开创性的论文都是用这些工具写的。到目前为止，它们已经被 [TensorFlow](https://github.com/tensorflow/tensorflow)（通常通过其高级 API [Keras](https://github.com/keras-team/keras) 使用）、[CNTK](https://github.com/Microsoft/CNTK)、[Caffe 2](https://github.com/caffe2/caffe2) 和 [Apache MXNet](https://github.com/apache/incubator-mxnet) 所取代。第三代工具，即用于深度学习的命令式工具，可以说是由 [Chainer](https://github.com/chainer/chainer) 率先推出的，它使用类似于 Python NumPy 的语法来描述模型。这个想法被 [PyTorch](https://github.com/pytorch/pytorch)、MXNet 的 [Gluon API](https://github.com/apache/incubator-mxnet) 和 [Jax](https://github.com/google/jax) 都采纳了
>“系统研究人员构建更好的工具”和“统计建模人员构建更好的神经网络”之间的分工大大简化了工作。

# 深度学习的特点
深度学习是机器学习的一个子集，但令人眼花缭乱的算法和应用程序集让人很难评估深度学习的具体成分是什么。这就像试图确定披萨所需的配料一样困难，因为几乎每种成分都是可以替代的。
深度学习是“深度”的，模型学习了许多“层”的转换，每一层提供一个层次的表示。例如，靠近输入的层可以表示数据的低级细节，而接近分类输出的层可以表示用于区分的更抽象的概念。由于_表示学习_（representation learning）目的是寻找表示本身，因此深度学习可以称为“多级表示学习”。
毋庸置疑，深度学习方法中最显著的共同点是使用端到端训练。也就是说，与其基于单独调整的组件组装系统，不如构建系统，然后联合调整它们的性能。
在过去的日子里，将机器学习应用于这些问题的关键部分是提出人工设计的特征工程方法，将数据转换为某种适合于浅层模型的形式。然而，与一个算法自动执行的数百万个选择相比，人类通过特征工程所能完成的事情很少。当深度学习开始时，这些*特征抽取器被自动调整的滤波器所取代*，产生了更高的精确度。
>因此，深度学习的一个关键优势是它不仅取代了传统学习管道末端的浅层模型，而且还取代了劳动密集型的特征工程过程。此外，通过取代大部分特定领域的预处理，深度学习消除了以前分隔计算机视觉、语音识别、自然语言处理、医学信息学和其他应用领域的许多界限，为解决各种问题提供了一套统一的工具。
 除了端到端的训练，人们正在经历从参数统计描述到*完全非参数模型*的转变。当数据稀缺时，人们需要依靠简化对现实的假设来获得有用的模型。当数据丰富时，可以用更准确地拟合实际情况的非参数模型来代替。在某种程度上，这反映了物理学在上个世纪中叶随着计算机的出现所经历的进步。现在人们可以借助于相关偏微分方程的数值模拟，而不是用手来求解电子行为的参数近似。这导致了更精确的模型，尽管常常以*牺牲可解释性*为代价。
 与以前工作的另一个不同之处是接受次优解，处理非凸非线性优化问题，并且愿意在证明之前尝试。
# 小结

-   机器学习研究计算机系统如何利用经验（通常是数据）来提高特定任务的性能。它结合了统计学、数据挖掘和优化的思想。通常，它是被用作实现人工智能解决方案的一种手段。
    
-   表示学习作为机器学习的一类，其研究的重点是如何自动找到合适的数据表示方式。深度学习是通过学习多层次的转换来进行的多层次的表示学习。
    
-   深度学习不仅取代了传统机器学习的浅层模型，而且取代了劳动密集型的特征工程。
    
-   最近在深度学习方面取得的许多进展，大都是由廉价传感器和互联网规模应用所产生的大量数据，以及（通过GPU）算力的突破来触发的。
    
-   整个系统优化是获得高性能的关键环节。有效的深度学习框架的开源使得这一点的设计和实现变得非常容易。