# <center>å®éªŒå››           å¾ªç¯ç¥ç»ç½‘ç»œ</center>
#### <center>å²³æ€æº    **120L021112**</center>


# 1. å®éªŒç¯å¢ƒ
`CUDA 12.1` ,  `pytorch-cuda=11.8` , `python 3.8`, `RTX2060`
# 2. å®éªŒå†…å®¹
>åˆ©ç”¨ Pytorch è‡ªå·±å®ç° RNNã€GRUã€LSTM å’Œ Bi-LSTM
>ä¸å¯ç›´æ¥è°ƒç”¨ nn. RNN (), nn. GRU (), nn. LSTM ()ã€‚
>A. åˆ©ç”¨ä¸Šè¿°å››ç§ç»“æ„è¿›è¡Œæ–‡æœ¬å¤šåˆ†ç±»ï¼ˆ60%ï¼‰
>è®¡ç®—æµ‹è¯•ç»“æœçš„å‡†ç¡®ç‡ã€å¬å›ç‡å’Œ F1 å€¼ï¼›
>å¯¹æ¯”åˆ†æå››ç§ç»“æ„çš„å®éªŒç»“æœã€‚
>B. ä»»é€‰ä¸Šè¿°ä¸€ç§ç»“æ„è¿›è¡Œæ¸©åº¦é¢„æµ‹ï¼ˆ40%ï¼‰
>ä½¿ç”¨äº”å¤©çš„æ¸©åº¦å€¼é¢„æµ‹å‡ºæœªæ¥ä¸¤å¤©çš„æ¸©åº¦å€¼ï¼›
>ç»™å‡ºä¸çœŸå®å€¼çš„å¹³å‡è¯¯å·®å’Œä¸­ä½è¯¯å·®ã€‚

## å®ç° RNNã€GRUã€LSTM å’Œ Bi-LSTM
### RNN
ç»™å®šä¸€ä¸ªè¾“å…¥åºåˆ— $ğ’™_1âˆ¶ğ‘‡ = (ğ’™_1, ğ’™_2, â€¦ , ğ’™_ğ‘¡, â€¦ , ğ’™_ğ‘‡)$ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œé€šè¿‡ä¸‹é¢å…¬å¼æ›´æ–°å¸¦åé¦ˆè¾¹çš„éšè—å±‚çš„æ´»æ€§å€¼ $ğ’‰_ğ‘¡$ ï¼š$ğ’‰_ğ‘¡ = ğ‘“(ğ’‰_ğ‘¡âˆ’1, ğ’™_ğ‘¡)$,
å…¶ä¸­ $ğ’‰_0 = 0ï¼Œğ‘“(â‹…)$ ä¸ºä¸€ä¸ªéçº¿æ€§å‡½æ•°ï¼Œå¯ä»¥æ˜¯ä¸€ä¸ªå‰é¦ˆç½‘ç»œï¼å¾ªç¯ç¥ç»ç½‘ç»œçš„æ‹Ÿåˆèƒ½åŠ›ä¹Ÿååˆ†å¼ºå¤§ã€‚
ä¸€ä¸ªå®Œå…¨è¿æ¥çš„å¾ªç¯ç½‘ç»œæ˜¯ä»»ä½•éçº¿æ€§åŠ¨åŠ›ç³»ç»Ÿçš„è¿‘ä¼¼å™¨ã€‚
![[Pasted image 20230524205657.png]]
ä¸€ä¸ª RNN ç¥ç»å…ƒå¦‚ä½•åœ¨ä¸€ä¸ªæ—¶é—´æ­¥é‡Œå¦‚ä½•è®¡ç®—éšè—çŠ¶æ€å’Œè¾“å‡ºï¼š
```python
def rnn(inputs, state, params):
    # inputså’Œoutputsçš†ä¸ºnum_stepsä¸ªå½¢çŠ¶ä¸º(batch_size, vocab_size)çš„çŸ©é˜µ
    W_xh, W_hh, b_h, W_hq, b_q = params
    H, = state
    outputs = []
    for X in inputs:
        H = nd.tanh(nd.dot(X, W_xh) + nd.dot(H, W_hh) + b_h)
        Y = nd.dot(H, W_hq) + b_q
        outputs.append(Y)
    return outputs, (H,)
```
ç”±äº RNN ä¸­å¯èƒ½å‡ºç°æ¢¯åº¦çˆ†ç‚¸ï¼Œå¯¼è‡´æˆ‘ä»¬ä¸€æ­¥èµ°åˆ°è§£ç©ºé—´å¤–ï¼Œå› æ­¤è¦é€šè¿‡è£å‰ªæ¢¯åº¦æ¥é¿å…è¿™ç§çŠ¶å†µã€‚
```python
def grad_clipping(params, theta, ctx):
    norm = nd.array([0], ctx)
    for param in params:
        norm += (param.grad ** 2).sum()
    norm = norm.sqrt().asscalar()
    if norm > theta:
        for param in params:
            param.grad[:] *= theta / norm
```

### GRU
GRU ç½‘ç»œå¼•å…¥é—¨æ§æœºåˆ¶æ¥æ§åˆ¶ä¿¡æ¯æ›´æ–°çš„æ–¹å¼ï¼å’Œ LSTM ä¸åŒï¼ŒGRU ä¸å¼•å…¥é¢å¤–çš„è®°å¿†å•å…ƒï¼ŒGRU ç½‘ç»œå¼•å…¥ä¸€ä¸ªæ›´æ–°é—¨ï¼ˆUpdate Gate) æ¥æ§åˆ¶å½“å‰çŠ¶æ€éœ€è¦ä»å†å²çŠ¶æ€ä¸­ä¿ç•™å¤šå°‘ä¿¡æ¯ï¼ˆä¸ç»è¿‡éçº¿æ€§å˜æ¢ï¼‰ï¼Œä»¥åŠéœ€è¦ä»å€™é€‰çŠ¶æ€ä¸­æ¥å—å¤šå°‘æ–°ä¿¡æ¯
å³ $ğ’‰_ğ‘¡ = ğ’›_ğ‘¡ âŠ™ ğ’‰_ğ‘¡âˆ’1 + (1 âˆ’ ğ’›_ğ‘¡) âŠ™ ğ‘”(ğ’™_ğ‘¡, ğ’‰_ğ‘¡âˆ’1;ğœƒ)$
GRU ç½‘ç»œç›´æ¥ä½¿ç”¨ä¸€ä¸ªé—¨æ¥æ§åˆ¶è¾“å…¥å’Œé—å¿˜ä¹‹é—´çš„å¹³è¡¡ï¼å½“ $ğ’›_ğ‘¡$ = 0 æ—¶ï¼Œå½“å‰çŠ¶æ€ $ğ’‰_ğ‘¡$ å’Œå‰ä¸€æ—¶åˆ»çš„çŠ¶æ€ $ğ’‰_ğ‘¡âˆ’1$ ä¹‹é—´ä¸ºéçº¿æ€§å‡½æ•°å…³ç³»ï¼›å½“ $ğ’›_ğ‘¡$ = 1 æ—¶ï¼Œ$ğ’‰_ğ‘¡$ å’Œ $ğ’‰_ğ‘¡âˆ’1$ ä¹‹é—´ä¸ºçº¿æ€§å‡½æ•°å…³ç³»ï¼
å…¶ä¸­ $ğ’‰_ğ‘¡$ è¡¨ç¤ºå½“å‰æ—¶åˆ»çš„å€™é€‰çŠ¶æ€ï¼Œ$ğ’“_ğ‘¡$ âˆˆ \[0, 1\]ğ· ä¸ºé‡ç½®é—¨, ç”¨æ¥æ§åˆ¶å€™é€‰çŠ¶æ€çš„è®¡ç®—æ˜¯å¦ä¾èµ–ä¸Šä¸€æ—¶åˆ»çš„çŠ¶æ€ $ğ’‰_{ğ‘¡âˆ’1}$ã€‚
ç»¼ä¸Šï¼ŒGRU ç½‘ç»œçš„çŠ¶æ€æ›´æ–°æ–¹å¼ä¸º
![[Pasted image 20230524212843.png]]
å½“ $ğ’›_ğ‘¡$ = 0, ğ’“ = 1 æ—¶ï¼ŒGRU ç½‘ç»œé€€åŒ–ä¸ºç®€å•å¾ªç¯ç½‘ç»œï¼›è‹¥ $ğ’›_ğ‘¡$ = 0, ğ’“ = 0 æ—¶ï¼Œå½“å‰çŠ¶æ€ $ğ’‰_ğ‘¡$ åªå’Œå½“å‰è¾“å…¥ $ğ’™_ğ‘¡$ ç›¸å…³ï¼Œå’Œå†å²çŠ¶æ€ $ğ’‰_{ğ‘¡âˆ’1}$ æ— å…³ã€‚
å¦‚å›¾ï¼š
![[Pasted image 20230524213056.png]]
æ ¹æ®é—¨æ§å¾ªç¯å•å…ƒçš„è®¡ç®—è¡¨è¾¾å¼å®šä¹‰æ¨¡å‹:
```python
def gru(inputs, state, params):
    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params
    H, = state
    outputs = []
    for X in inputs:
        Z = nd.sigmoid(nd.dot(X, W_xz) + nd.dot(H, W_hz) + b_z)
        R = nd.sigmoid(nd.dot(X, W_xr) + nd.dot(H, W_hr) + b_r)
        H_tilda = nd.tanh(nd.dot(X, W_xh) + nd.dot(R * H, W_hh) + b_h)
        H = Z * H + (1 - Z) * H_tilda
        Y = nd.dot(H, W_hq) + b_q
        outputs.append(Y)
    return outputs, (H,)
```

### LSTM
LSTM ä¸­å¼•å…¥äº† 3 ä¸ªé—¨ï¼Œå³è¾“å…¥é—¨ï¼ˆinput gateï¼‰ã€é—å¿˜é—¨ï¼ˆforget gateï¼‰å’Œè¾“å‡ºé—¨ï¼ˆoutput gateï¼‰å’Œä¼ ç»Ÿçš„è®°å¿† cellã€‚æ•´ä¸ªè®°å¿†æœºåˆ¶æ›´åŠ å¤æ‚ï¼š
é•¿çŸ­æœŸè®°å¿†çš„é—¨çš„è¾“å…¥å‡ä¸ºå½“å‰æ—¶é—´æ­¥è¾“å…¥ $X_t$ ä¸ä¸Šä¸€æ—¶é—´æ­¥éšè—çŠ¶æ€ $H_{tâˆ’1}$ï¼Œè¾“å‡ºç”±æ¿€æ´»å‡½æ•°ä¸º sigmoid å‡½æ•°çš„å…¨è¿æ¥å±‚è®¡ç®—å¾—åˆ°ã€‚
ï¼ˆ1ï¼‰ é—å¿˜é—¨ ğ’‡ğ‘¡ æ§åˆ¶ä¸Šä¸€ä¸ªæ—¶åˆ»çš„å†…éƒ¨çŠ¶æ€ ğ’„ğ‘¡âˆ’1 éœ€è¦é—å¿˜å¤šå°‘ä¿¡æ¯ï¼
ï¼ˆ2ï¼‰ è¾“å…¥é—¨ ğ’Šğ‘¡ æ§åˆ¶å½“å‰æ—¶åˆ»çš„å€™é€‰çŠ¶æ€ Ìƒğ’„ğ‘¡ æœ‰å¤šå°‘ä¿¡æ¯éœ€è¦ä¿å­˜ï¼
ï¼ˆ3ï¼‰ è¾“å‡ºé—¨ ğ’ğ‘¡ æ§åˆ¶å½“å‰æ—¶åˆ»çš„å†…éƒ¨çŠ¶æ€ ğ’„ğ‘¡ æœ‰å¤šå°‘ä¿¡æ¯éœ€è¦è¾“å‡ºç»™å¤–éƒ¨çŠ¶
æ€ğ’‰ğ‘¡
è¿™ä¸‰ä¸ªé—¨çš„å–å€¼ä¸ºï¼ˆ0ï¼Œ1ï¼‰
$i_t = ğœ(ğ‘¾_iğ’™_ğ‘¡ + ğ‘¼_iğ’‰_ğ‘¡âˆ’1 + ğ’ƒ_i)$
$ğ’‡_ğ‘¡ = ğœ(ğ‘¾_ğ‘“ğ’™_ğ‘¡ + ğ‘¼_ğ‘“ğ’‰_ğ‘¡âˆ’1 + ğ’ƒ_ğ‘“)$
$o_t = ğœ(ğ‘¾_oğ’™_ğ‘¡ + ğ‘¼_oğ’‰_ğ‘¡âˆ’1 + ğ’ƒ_o)$
å¦‚å›¾ï¼Œå…¶è®¡ç®—è¿‡ç¨‹ä¸ºï¼š1ï¼‰é¦–å…ˆåˆ©ç”¨ä¸Šä¸€æ—¶åˆ»çš„å¤–éƒ¨çŠ¶æ€ $ğ’‰_{tâˆ’1}$ å’Œå½“å‰æ—¶åˆ»çš„è¾“å…¥ $ğ’™_ğ‘¡$ ç®—å‡ºä¸‰ä¸ªé—¨ï¼Œä»¥åŠå€™é€‰çŠ¶æ€ $ğ’„_ğ‘¡'$    2ï¼‰ç»“åˆé—å¿˜é—¨ $ğ’‡_ğ‘¡$ å’Œè¾“å…¥é—¨ $ğ’Š_ğ‘¡$ æ¥æ›´æ–°è®°å¿†å•å…ƒ $ğ’„_ğ‘¡$ï¼›3ï¼‰ç»“åˆè¾“å‡ºé—¨ $ğ’_ğ‘¡$ï¼Œå°†å†…éƒ¨çŠ¶æ€çš„ä¿¡æ¯ä¼ é€’ç»™å¤–éƒ¨çŠ¶æ€ $ğ’‰_t$
![[Pasted image 20230524214655.png]]
```python
def lstm(inputs, state, params):
    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,
     W_hq, b_q] = params
    (H, C) = state
    outputs = []
    for X in inputs:
        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)
        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)
        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)
        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)
        C = F * C + I * C_tilda
        H = O * torch.tanh(C)
        Y = (H @ W_hq) + b_q
        outputs.append(Y)
    return torch.cat(outputs, dim=0), (H, C)
```

### Bi_LSTM
åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œç›¸æ¯”æ­£å‘çš„ LSTM æ·»åŠ äº†åå‘ä¼ é€’ä¿¡æ¯çš„éšè—å±‚ï¼Œä»¥ä¾¿æ›´çµæ´»åœ°å¤„ç†åºåˆ—ä¿¡æ¯ã€‚
![[Pasted image 20230524215136.png]]
ç”±äºåŒå‘å¾ªç¯ç¥ç»ç½‘ç»œä½¿ç”¨äº†è¿‡å»çš„å’Œæœªæ¥çš„æ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸èƒ½ç›²ç›®åœ°å°†è¿™ä¸€è¯­è¨€æ¨¡å‹åº”ç”¨äºä»»ä½•é¢„æµ‹ä»»åŠ¡ã€‚
```python
    def bi_lstm(self, inputs, state, params):
        W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_xi_b, W_hi_b, b_i_b, W_xf_b, W_hf_b, b_f_b, W_xo_b, W_ho_b, b_o_b, W_xc_b, W_hc_b, b_c_b, W_hq, b_q = params
        (H, C), (H_b, C_b) = state
        outputs = []
        H_forward = []
        for X in inputs:
            I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)
            F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)
            O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)
            C_curved = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c) 
            C = F * C + I * C_curved  # è®¡ç®—C
            H = O * torch.tanh(C)  # è®¡ç®—H
            H_forward.append(H)
        inputs_reverse = torch.flip(inputs, dims=[0])
        H_backward = []
        for X in inputs_reverse:
            # åå‘
            I_b = torch.sigmoid((X @ W_xi_b) + (H_b @ W_hi_b) + b_i_b)
            F_b = torch.sigmoid((X @ W_xf_b) + (H_b @ W_hf_b) + b_f_b)
            O_b = torch.sigmoid((X @ W_xo_b) + (H_b @ W_ho_b) + b_o_b)
            C_curved_b = torch.tanh((X @ W_xc_b) + (H_b @ W_hc_b) + b_c_b)  
            C_b = F_b * C_b + I_b * C_curved_b  # è®¡ç®—C
            H_b = O_b * torch.tanh(C_b)  # è®¡ç®—H
            H_backward.append(H_b)
        length = inputs.shape[0]
        for i in range(length):
            # æ‹¼æ¥H,H_b
            H = H_forward[i]
            H_b = H_backward[length - i - 1]
            H = torch.cat((H, H_b), dim=1)
            # è®¡ç®—è¾“å‡º
            Y = H @ W_hq + b_q
            outputs.append(Y)
        # æœ€ç»ˆæŒ‰è¡Œæ‹¼æ¥æ‰€æœ‰ç»“æœ
        return outputs = torch.cat(outputs, dim=0)
```
# 3 å®éªŒç»“æœ
## 3.1 åˆ†åˆ«ç”¨å››ä¸ªæ¨¡å‹å¯¹ online_shopping_10_cats è¿›è¡Œåˆ†ç±»
#### RNN
`lr=1e-3 `          
`weight_decay=1e-4
`epochs=20`
![[Pasted image 20230523233157.png]]
![[Pasted image 20230524021801.png]]
æœ€ç»ˆåœ¨æµ‹è¯•é›†ä¸Šçš„ `precision` æ˜¯ **0.76**
## GRU
`lr=1e-3 `          
`weight_decay=1e-4
`epochs=20`
![[Pasted image 20230524000141.png]]
![[Pasted image 20230524021823.png]]
æœ€ç»ˆåœ¨æµ‹è¯•é›†ä¸Šçš„ `precision` æ˜¯ **0.80**
æˆ‘ä»¬å¯ä»¥åœ¨ä½¿ç”¨åŒæ ·çš„å­¦ä¹ ç‡å’Œä¼˜åŒ–å™¨ç®—æ³•æƒ…å†µä¸‹å¯ä»¥çœ‹å‡º GRU ç›¸æ¯”æ™®é€š RNN çš„æ”¶æ•›é€Ÿåº¦æå‡é£å¿«ï¼Œåœ¨ç¬¬ä¸€ä¸ª epoch å°±æœ‰äº†ç›¸å½“æƒŠäººçš„æ•ˆæœï¼Œ10 ä¸ª epoch ç»“æŸååŸºæœ¬å·²ç»æ”¶æ•›äº†ï¼Œä¹‹åå…¶ loss ä¹Ÿæ— æ³•å¾—åˆ°å®é™…å‡å°ï¼Œä½† RNN æ”¶æ•›æ…¢å¾ˆå¤šï¼Œ20 ä¸ª epoch åŸºæœ¬ loss éƒ½åœ¨é€æ­¥å‡å°ï¼Œæœ€ç»ˆæµ‹è¯•é›†æ•ˆæœ GRU ä¹Ÿèƒ½ç•¥èƒœä¸€ç­¹ã€‚
## LSTM
`lr=1e-3`
`weight_decay=1e-4`
`epochs=10`
![[Pasted image 20230524020705.png]]
![[Pasted image 20230524021837.png]]
æœ€ç»ˆåœ¨æµ‹è¯•é›†ä¸Šçš„ `precision` æ˜¯ **0.87**
LSTM åœ¨åŒæ ·ä½¿ç”¨ Adam ï¼Œå­¦ä¹ ç‡ç›¸åŒçš„æƒ…å†µä¸‹æ”¶æ•›ä¹Ÿéå¸¸çš„å¿«ï¼Œå¹¶ä¸”æœ€ç»ˆåœ¨æµ‹è¯•é›†ä¸Šçš„æ•ˆæœä¹Ÿç¡®å®æ¯” GRU å¥½ä¸€äº›ã€‚è™½ç„¶ LSTM æ¨¡å‹æ— æ¯”å¤æ‚ï¼Œä½†ç¡®å®æœ‰ä¸é”™çš„è¡¨ç°ã€‚
## BiLSTM
![[Pasted image 20230524020528.png]]
![[Pasted image 20230524021850.png]]
æœ€ç»ˆåœ¨æµ‹è¯•é›†ä¸Šçš„ `precision` æ˜¯ **0.87**
Bi_LSTM çš„è®­ç»ƒé€Ÿåº¦ç›¸æ¯” LSTM æ˜æ˜¾æ”¾æ…¢ï¼Œå‡ ä¹æ˜¯ LSTM çš„ä¸¤å€è®­ç»ƒé€Ÿåº¦ã€‚è™½ç„¶æœ€ç»ˆçš„è®­ç»ƒ loss è¦æ¯” LSTM ä½ä¸€ä¸¢ä¸¢ï¼Œä½†å…¶å·®è·è¿‡å°ï¼Œè€Œä¸”åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°ä¸ LSTM ä¹ŸåŸºæœ¬ç›¸å½“ï¼ŒèŠ±äº†å¤šä¸€å€çš„æ—¶é—´ï¼Œä½†å¹¶æ²¡æœ‰å•¥å®é™…çš„æ•ˆç›Šã€‚
## 3.2 é€‰å–ä¸€ä¸ªæ¨¡å‹è¿›è¡Œæ¸©åº¦é¢„æµ‹
æ•°æ®é›†ä¸º `jena_climate_2009_2016`
ç»™å®šå‰äº”å¤©çš„æ•°æ®ï¼Œé¢„æµ‹åä¸¤å¤©çš„æ•°æ®ã€‚
æˆ‘é€‰æ‹©çš„æ¨¡å‹æ˜¯**LSTM**ã€‚
è®­ç»ƒè¿‡ç¨‹ã€‚
![[Pasted image 20230524152515.png]]
æµ‹è¯•é›†ä¸Šçš„æµ‹è¯•ç»“æœ
![[Pasted image 20230524152713.png]]
mean_error = 3.7664
ä¸­ä½è¯¯å·®=3.1463ã€‚


