## [内存次序](https://mq-b.github.io/ModernCpp-ConcurrentProgramming-Tutorial/md/05%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C.html#%E5%86%85%E5%AD%98%E6%AC%A1%E5%BA%8F)

### [前言](https://mq-b.github.io/ModernCpp-ConcurrentProgramming-Tutorial/md/05%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C.html#%E5%89%8D%E8%A8%80)

事实上我们在前面就用到了不少的内存次序，只不过一直没详细展开讲解。

在开始学习之前，我们需要强调一些基本的认识：

1. **内存次序是非常底层知识**：对于普通开发者来说，了解内存次序并非硬性需求。如果您主要关注业务开发，可以直接跳过本节内容。如果您对内存次序感兴趣，则需要注意其复杂性和难以观察的特性，这将使学习过程具有一定挑战性。
    
2. **内存次序错误的使用难以察觉**：即使通过多次（数以万计）运行也难以发现。这是因为许多内存次序问题是由于极端的、少见的情况下的竞争条件引起的，而这些情况很难被重现。此外，即使程序在某些平台上运行正常，也不能保证它在其他平台上也能表现良好，因为不同的 CPU 和编译器可能对内存操作的顺序有不同的处理（例如 x86 架构内存模型：Total Store Order (TSO)，是比较严格的内存模型）。因此，开发者必须依赖自己的知识和经验，以及可能的测试和调试技术，来发现和解决内存次序错误。
    

错误难以被我们观察到的原因其实可以简单的说：

- **CPU 与编译器不是神经病，没有_好处_不会闲的没事给你指令重排**。

---

- 编译器重排：编译器在编译代码时，为了提高性能，可以按照一定规则重新安排代码的执行顺序。例如，可以将不相关的指令重排，使得 CPU 流水线更加高效地执行指令。编译器优化需要遵守一个“[**如同规则**](https://zh.cppreference.com/w/cpp/language/as_if)（as-if rule）”，即不可改变可观察的副作用。
    
- **CPU 重排**：（更隐晦和更难察觉，一个可执行文件，每次执行结果不一样）CPU 在运行程序时，也会对指令进行重排，以提高执行效率，减少等待时间。这种重排通常遵循一些硬件层面的优化规则，如内存访问的优化。
    

你们可能还有疑问：“**单线程能不能指令重排**？”

CPU 的指令重排必须遵循一定的规则，以确保程序的**可观察副作用**不受影响。对于单线程程序，CPU 会保证外部行为的一致性。对于多线程程序，需要开发者使用同步原语来显式地控制内存操作的顺序和可见性，确保多线程环境下的正确性。而标准库中提供的原子对象的原子操作，还可以设置内存次序。

那有没有可能：

- “_end 重排到 start 前面了！指令重排了！_”

这也就是前面说的，把 CPU 与编译器当神经病。各位写代码难道还要考虑下面这段，会不会指令重排导致先输出 `end` 吗？这显然不现实。

```CPP
print("start"); // 1
print("end");   // 2
```

不禁止就是有可能，但是我们无需在乎，**就算真的 CPU 将 end 重排到 start 前面了，也得在可观测行为发生前回溯了**。所以我一直在强调，这些东西，**我们无需在意**。

好了，到此，基本认识也就足够了，以上的示例更多的是泛指，知道其表达的意思就好，这些还是简单直接且符合直觉的。

### [可见](https://mq-b.github.io/ModernCpp-ConcurrentProgramming-Tutorial/md/05%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C.html#%E5%8F%AF%E8%A7%81)

**可见** 是 C++ 多线程并发编程中的一个重要概念，它描述了一个线程中的数据修改对其他线程的可见程度。具体来说，如果线程 A 对变量 x 进行了修改，那么**其他线程 B 是否能够看到线程 A 对 x 的修改**，就涉及到可见的问题。

在讨论多线程的内存模型和执行顺序时，虽然经常会提到 CPU 重排、编译器优化、缓存等底层细节，但真正核心的概念是_可见_，而不是这些底层实现细节。

**C++ 标准中的可见**：

- 如果线程 A 对变量 x 进行了修改，而线程 B 能够读取到线程 A 对 x 的修改，那么我们说线程 B 能看到线程 A 对 x 的修改。也就是说，线程 A 的修改对线程 B 是_**可见**_的。

C++ 标准通过内存序（memory order）来定义如何确保这种_可见_，而不必直接关心底层的 CPU 和编译器的具体行为。内存序提供了操作之间的顺序关系，确保即使存在 CPU 重排、编译器优化或缓存问题，线程也能正确地看到其他线程对共享数据的修改。

例如，通过使用合适的内存序（如 memory_order_release 和 memory_order_acquire），可以确保线程 A 的写操作在其他线程 B 中是可见的，从而避免数据竞争问题。

总结：

- _可见_ 关注的是线程之间的数据一致性，而不是底层的实现细节。
    
- 使用 C++ 的内存序机制可以确保数据修改的可见，而不必过多关注具体的 CPU 和编译器行为。
    

这种描述方式可以帮助更清楚地理解和描述多线程并发编程中如何通过 C++ 标准的内存模型来确保线程之间的数据一致性，而无需太多关注底层细节。

---

我知道各位肯定有疑问，我们大多数时候写多线程代码都从来没使用过内存序，一般都是互斥量、条件变量等高级同步设施，这没有可见性的问题吗？

没有，这些设施自动确保数据的可见性。例如： `std::mutex` 的 `unlock()` 保证：

- 此操作_同步于_任何后继的取得同一互斥体所有权的锁定操作。

也就是 [`unlock()`](https://zh.cppreference.com/w/cpp/thread/mutex/unlock) _同步于_ `lock()`。

“_同步于_”：操作 A 的完成会确保操作 B 在其之后的执行中，能够看到操作 A 所做的所有修改。

也就是说：

- `std::mutex` 的 `unlock()` 操作_同步于_任何随后的 `lock()` 操作。这意味着，线程在调用 `unlock()` 时，对共享数据的修改会对之后调用 `lock()` 的线程_可见_。

###   [`std::memory_order`](https://mq-b.github.io/ModernCpp-ConcurrentProgramming-Tutorial/md/05%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C.html#std-memory-order)

`std::memory_order` 是一个枚举类型，用来指定原子操作的内存顺序，影响这些操作的行为。

```CPP
typedef enum memory_order {
    memory_order_relaxed,
    memory_order_consume,
    memory_order_acquire,
    memory_order_release,
    memory_order_acq_rel,
    memory_order_seq_cst
} memory_order;

// C++20 起则为：

enum class memory_order : /* 未指明 */ {
    relaxed, consume, acquire, release, acq_rel, seq_cst
};
inline constexpr memory_order memory_order_relaxed = memory_order::relaxed;
inline constexpr memory_order memory_order_consume = memory_order::consume;
inline constexpr memory_order memory_order_acquire = memory_order::acquire;
inline constexpr memory_order memory_order_release = memory_order::release;
inline constexpr memory_order memory_order_acq_rel = memory_order::acq_rel;
inline constexpr memory_order memory_order_seq_cst = memory_order::seq_cst;
```

这 6 个常量，每一个常量都表示不同的内存次序。

大体来说我们可以将它们分为三类。

1. `memory_order_relaxed` 宽松定序：不是定序约束，**仅对此操作要求原子性**。
2. `memory_order_seq_cst` 序列一致定序，这是库中所有原子操作的**默认行为**，也是**最严格的内存次序**，是**绝对安全**的。

剩下的就是第三类。

### [其它概念](https://mq-b.github.io/ModernCpp-ConcurrentProgramming-Tutorial/md/05%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C.html#%E5%85%B6%E5%AE%83%E6%A6%82%E5%BF%B5)

####  [`x86` 和 `ARM` 的内存模型：强一致性与弱一致性](https://mq-b.github.io/ModernCpp-ConcurrentProgramming-Tutorial/md/05%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C.html#x86-%E5%92%8C-arm-%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-%E5%BC%BA%E4%B8%80%E8%87%B4%E6%80%A7%E4%B8%8E%E5%BC%B1%E4%B8%80%E8%87%B4%E6%80%A7)

**内存模型是软件与实现之间的一种约定契约**。它定义了在多线程或并发环境中，如何对内存操作的顺序和一致性进行规范，以确保程序的正确性和可靠性。

C++ 标准为我们定义了 *C++ 标准内存模型*，使我们能够无需关心底层硬件环境就编写出跨平台的应用程序。不过，了解底层硬件架构的内存模型对扩展知识面和深入理解编程细节也非常有帮助。

最经典与常见的两种 CPU 指令集架构就是：`x86` 与 `ARM`。

- `x86` 架构：是一种复杂指令集计算（[CISC](https://zh.wikipedia.org/wiki/%E8%A4%87%E9%9B%9C%E6%8C%87%E4%BB%A4%E9%9B%86%E9%9B%BB%E8%85%A6)）架构，因其强大的性能被广泛应用于桌面电脑、笔记本电脑和服务器中。`x86` 架构采用的是 TSO（Total Store Order）[**内存一致性模型**](https://jamesbornholt.com/blog/memory-models/)，是一种**强一致性模型**，**简化了多线程编程中的内存同步问题**（后文中会提到）。
    
- `ARM` 架构：是一种精简指令集计算（[RISC](https://zh.wikipedia.org/wiki/%E7%B2%BE%E7%AE%80%E6%8C%87%E4%BB%A4%E9%9B%86%E8%AE%A1%E7%AE%97%E6%9C%BA)）架构，因其高能效和低功耗特点广泛应用于移动设备、嵌入式系统和物联网设备中。`ARM` 架构采用的是**弱序内存模型**（[weakly-ordered memory](https://developer.arm.com/documentation/102336/0100/Memory-ordering)），允许**更灵活**的内存优化，但这需要程序员使用内存屏障等机制来确保正确性。
    

这两种架构在设计理念和应用领域上存在显著差异，这也是它们在不同应用场景中表现出色的原因。

如果你从事嵌入式系统或者学术研究等，可能也听说过 `RISC-V` 架构，它目前在国内的应用也逐渐增多。

RISC-V 是一种开源的精简指令集计算（RISC）架构，旨在提供一种高效、模块化且开放的指令集。与 x86 和 ARM 架构不同，RISC-V 的设计目标是简化指令集，同时保持高度的灵活性和扩展性。它在内存模型方面也有自己独特的特性。

RISC-V 采用的也是**弱序内存模型**（weakly-ordered memory model），这与 x86 的强一致性模型（TSO）和 ARM 的弱一致性模型有所不同。你可能会有疑问：

- `ARM` 和 `RISC-V` 都是弱序内存模型，为什么不同？

各位一定要区分，这种强弱其实也只是一种分类而已，不同的指令集架构大多都还是有所不同的，并不会完全一样。例如： `x86` 的 TSO（Total Store Order）是强一致性模型的一种，但并不是所有强一致性模型都是 TSO。



---

