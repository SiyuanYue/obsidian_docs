# <center>基于 CIFAR-10 数据集的图像分类</center>
### <p align="right">——模式识别与深度学习实验一报告</p>
### <center> 120L021112           岳思源</center>
# 1. 题目选取
我选区的题目是基于 `CIFAR-10、CIFAR-100` 数据集的图像识别，并对比传统的 *最大熵模型（LogisticRegression）*，*SVM 机器学习模型*和一个简单的*三层 CNN 卷积神经网络模型*和一个达到 *16 层较复杂的神经网络 VGG16*。
**选择这个数据集的原因**：
> CIFAR-10 是一个更接近普适物体的彩色图像数据集。CIFAR-10 是由 Hinton 的学生 Alex Krizhevsky 和 Ilya Sutskever 整理的一个用于识别普适物体的小型数据集。一共包含 10 个类别的 RGB 彩色图片：飞机（ airplane ）、汽车（ automobile ）、鸟类（ bird ）、猫（ cat ）、鹿（ deer ）、狗（ dog ）、蛙类（ frog ）、马（ horse ）、船（ ship ）和卡车（ truck ）。  
> 每个图片的尺寸为 32 × 32 ，每个类别有 6000 个图像，数据集中一共有 50000 张训练图片和 10000 张测试图片。
> 与 `MNIST` 数据集相比， CIFAR-10 有以下不同点
> 1. CIFAR-10 是 3 通道的彩色 RGB 图像，而 MNIST 是灰度图像。
> 2. CIFAR-10 的图片尺寸为 32 × 32 ，而 MNIST 的图片尺寸为 28 × 28 ，比 MNIST 稍大。
> 3. 相比于手写字符， CIFAR-10 含有的是现实世界中真实的物体，不仅噪声很大，而且物体的比例、特征都不尽相同，这为识别带来很大困难。直接的线性模型如 Softmax 在 CIFAR-10 上表现得很差。

我更希望选择的数据集有一定普适性和代表度，并能够体现出接下来在其之上训练不同的模型相比较的*差别*并更好的分析其中的原因。

# 2. 数据准备与模型选择
## 2.1 数据准备
前面已经提到采取 CIFAR-10 彩色图像数据集，由于方便集成，我们直接用 `PyTorch` 上的 `datasets` 接口来下载数据：
```python
import os
import urllib.request
import torch
import torchvision
import torchvision.transforms as transforms
# 定义数据增强和预处理操作
transform_train = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(32, padding=4),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)
```
## 2.2 模型选择
首先我选取了两个传统的机器学习模型最大熵模型（LogisticRegression）和线性支持向量机模型：
>最大熵 Logistic Regression 是一种广义线性模型，它使用逻辑函数将线性组合的特征映射到概率空间中，从而得到分类的概率。它最大化训练样本的信息熵，通过最大熵原理来确定模型参数，使得在所有可能的参数下，模型的熵最大。最大熵 Logistic Regression 通过极大似然估计的方式来求解模型参数，可以用于分类和概率估计等任务。

>线性支持向量机是一种最大间隔分类器，其目的是找到一个超平面，能够将两个不同类别的数据分离开来，并且使得分类边界与最近的数据点之间的距离最大化。线性支持向量机可以通过对偶问题来求解，将数据点映射到高维空间，从而得到更好的分类效果。它具有良好的泛化性能，可以处理高维数据，是常用的分类器之一。

还选取了两个神经网络模型：
a.   一个简单的 CNN 网络,它有三个卷积层和两个全连接层。
在每个卷积层中，使用了一个卷积操作（Conv2d）和一个批标准化操作（BatchNorm2d），然后通过ReLU激活函数进行激活，并使用最大池化（Max Pooling）降采样。在全连接层中，也使用了 ReLU 激活函数。
b.  选择了经典的VGGNet 16
>2014年，牛津大学计算机视觉组（**V**isual **G**eometry **G**roup）和Google DeepMind公司一起研发了新的卷积神经网络，并命名为VGGNet。
>VGG 的结构与 AlexNet 类似，区别是深度更深，但形式上更加简单。VGG由5层卷积层、3层全连接层、1层softmax输出层构成，层与层之间使用maxpool（最大化池）分开，所有隐藏层的激活单元都采用ReLU函数。
-   VGG11：包含8个卷积层和3个全连接层；
-   VGG13：包含10个卷积层和3个全连接层；
-   VGG16：包含13个卷积层和3个全连接层；
-   VGG19：包含 16 个卷积层和 3 个全连接层。

VGGNet 相比于传统的 CNN 模型，采用了*更深的网络结构*，可以更好地学习图像中的特征。
# 3 模型训练与结果对比
## 3.1 模型训练与保存：
由于通过 pytorch 集成的接口导入数据，对于两个机器学习方法，还需要数据预处理一下：
```python
import numpy as np
# 将图像矩阵展平为一维向量

X_train = []
y_train = []
for data, target in trainloader:
    X_train.append(data.view(data.size(0), -1).numpy())
    y_train.append(target.numpy())
X_train = np.concatenate(X_train, axis=0)
y_train = np.concatenate(y_train, axis=0)

X_test = []
y_test = []
for data, target in testloader:
    X_test.append(data.view(data.size(0), -1).numpy())
    y_test.append(target.numpy())
X_test = np.concatenate(X_test, axis=0)
y_test = np.concatenate(y_test, axis=0)
```
### 3.1.1 训练最大熵（LogisticRegression）模型
调用 sklearn 库，训练模型保存为 `LR_cifar10. pkl`
```python
import warnings
from sklearn.linear_model import LogisticRegression
warnings.filterwarnings("ignore")
clf = LogisticRegression(solver="saga")
clf.fit(X_train, y_train)
with open('LR_cifar10.pkl', 'wb') as f:
    pickle.dump(clf, f)
```
### 3.1.2 训练线性支持向量机模型
```python
from sklearn.svm import LinearSVC
classifier = LinearSVC(C=10, random_state=42)
# 训练分类器
classifier.fit(X_train, y_train)
with open('LSVM_cifar10.pkl', 'wb') as f:
    pickle.dump(clf, f)
```
### 3.1.3 训练 CNN 模型：
1. 定义模型：
```python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)
        self.bn3 = nn.BatchNorm2d(256)
        self.fc1 = nn.Linear(256*4*4, 512)
        self.fc2 = nn.Linear(512, 10)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.bn3(self.conv3(x)))
        x = F.max_pool2d(x, 2)
        x = x.view(-1, 256*4*4)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

```
2. 定义损失函数和优化器
```python
import torch.optim as optim
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)
```
3. 训练网络
```python
for epoch in range(10):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % 100 == 99:
            print('[%d, %5d] loss: %.3f' %
                  (epoch+1, i+1, running_loss/100))
            running_loss = 0.0
```
![[Pasted image 20230501012056.png]]
### 3.1.4 训练 VGGnet 模型
```python
class VGG(nn.Module):
    def __init__(self, vgg_name):
        super(VGG, self).__init__()
        self.features = self._make_layers(cfg[vgg_name])
        self.classifier = nn.Linear(512, 10)
    
    def forward(self, x):
        out = self.features(x)
        out = out.view(out.size(0), -1)
        out = self.classifier(out)
        return out
    
    def _make_layers(self, cfg):
        layers = []
        in_channels = 3
        for x in cfg:
            if x == 'M':
                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
            else:
                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),
                           nn.BatchNorm2d(x),
                           nn.ReLU(inplace=True)]
                in_channels = x
        
        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]
        return nn.Sequential(*layers)
```
定义模型的超参数并进行训练：
```python
cfg = {
    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],
    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']
}
net4 = VGG('VGG16')
mlps = [net4.to(device)]
optimizer = torch.optim.Adam([{"params": mlp.parameters()} for mlp in mlps], lr=LR)
loss_function = nn.CrossEntropyLoss()
for ep in range(EPOCHES):
    for img, label in trainloader:
        img, label = img.to(device), label.to(device)
        optimizer.zero_grad()
        for mlp in mlps:
            mlp.train()
            out = mlp(img)
            loss = loss_function(out, label)
            loss.backward()
        optimizer.step()
```

## 3.2 读取训练好的模型进行测试分析结果
1. LogisticRegression:
```python
y_pred_LR = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred_LR)
print('Accuracy: {:.2f}%'.format(accuracy * 100))
# 输出混淆矩阵和分类报告
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_LR))
print("Classification Report:")
print(classification_report(y_test, y_pred_LR))
```
![[Pasted image 20230501011301.png]]
2. LSVM:
```python
with open('LSVM_cifar10.pkl', 'rb') as f:
    svm_model = pickle.load(f)
# 在测试集上进行预测
y_pred_LSVC = classifier.predict(X_test)
# 输出混淆矩阵和分类报告
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Classification Report:")
print(classification_report(y_test, y_pred))
```

![[Pasted image 20230501013810.png]]
3. CNN:

![[Pasted image 20230501011506.png]]
4. VGGNet:

![[Pasted image 20230501015527.png]]

---
# 结果分析
| 模型                                                                                                                                                                                                                                                                                                                                                                                                             | ACC   |
|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------|
| Logistic Regression                                                                                                                                                                                                                                                                                                                                                                                            |   35% |
| <span style="font-family: &quot; HarmonyOS Sans&quot;, &quot;??&quot;, &quot; Microsoft YaHei UI&quot;, &quot;??&quot;, &quot;??&quot;, ui-sans-serif, -apple-system, BlinkMacSystemFont, &quot; Segoe UI&quot;, Roboto, Inter, &quot; Apple Color Emoji&quot;, &quot; Segoe UI Emoji&quot;, &quot; Segoe UI Symbol&quot;, &quot; Microsoft YaHei Light&quot;, sans-serif; caret-color: rgb (56, 58, 66);">LSVM</span> |   54% |
|                                                                                                                                                                                                                                                                                                                                                                                                          3 CNN |   78% |
| VGGNet16                                                                                                                                                                                                                                                                                                                                                                                                       | 89.3% |  
我们可以看到四种模型在该数据集上图像识别分类的性能差距还是相当大的。
Logistic Regression 模型性能最差，LSVM 模型强于 LR。但两种神经网络模型的表现要显著优于 LSVM, 其中 VGGNet16 因为卷积层数更深，效果优于 3 层卷积层的 CNN，这是意料之内的。
进一步，我们来分析一下 LSVM 在该问题上要显著优于 Logistic Regression 的原因：
1.  非线性决策边界：LSVM 模型使用非线性的核函数，能够处理非线性问题，并且可以得到更好的决策边界。
2.  可扩展性：LSVM 模型使用了分层的方法，将图像分解为不同的部分，分别进行识别和分类，这种方法可以处理更大规模的数据，并且可以很好地应用于图像检索和目标跟踪等领域。
3. Logistic Regression 对于图像分类来说较难找到何时有效的特征约束，而这会直接影响 Logistic Regression 的分类效果。对于图像这种高维数据，如何提取有用的特征并不是一件容易的事情。

CNN 效果要优于两种传统机器学习这不难预料，但神经网络模型在数据预处理上也是要更方便的，框架的统一会极大的降低门槛，这可能也是深度学习兴盛的原因之一。

