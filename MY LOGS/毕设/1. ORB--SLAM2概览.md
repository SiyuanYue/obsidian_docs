# 1 概览

查看 [ORB-SLAM2笔记01\_ORB-SLAM2代码运行流程](https://www.yuque.com/chenhai-7zi1m/se4n14/udvggt#1911df30)

## 目录
```
inlcude/ 头文件 每个头文件对应一个类
src/          源文件 类的实现
examples/   make编译生成的官方demo
	Monu.../
	RGBD/
		asscations/ 彩色图像和深度图的匹配文件
		rbgd_tum.cc 处理TUM数据集的源文件
		TUM1.yaml 配置文件
		...
	Stereo/
	ROS/
```

## 运行官方Demo  和数据集
以TUM数据集为例,运行Demo的命令:  
`./Examples/RGB-D/rgbd_tum Vocabulary/ORBvoc.txt Examples/RGB-D/TUM1.yaml PATH_TO_SEQUENCE_FOLDER ASSOCIATIONS_FILE`
执行 `./Examples/RGB-D/rgbd_tum`
第一个文件 `Vocabulary/ORBvoc.txt`  词袋 ORB3中优化成了二进制文件加速 （好像并没有），每一行是个描述子 
第二个文件 `Examples/RGB-D/TUM1.yaml` 配置文件
第三个文件 `PATH_TO_SEQUENCE_FOLDER` 数据集路径
第四个文件 `ASSOCIATIONS_FILE` 配准文件

###  `rgbd_tum.cc` 的源码大致步骤

#### step1 . 读取图片及左右目关联信息

#### step2 . 检查图片文件及输入文件的一致性

#### step3 . 创建SLAM对象, 它是一个 `ORB_SLAM2::System` 类型变量
`ORB_SLAM2::System SLAM(argv[1], argv[2], ORB_SLAM2::System::RGBD, true);`
#### step4 . 循环遍历图片, 进行SLAM
##### step4 .1. 读取当前图片
```CPP
	imRGB = cv::imread(string(argv[3]) + "/" + vstrImageFilenamesRGB[ni], CV_LOAD_IMAGE_UNCHANGED);
	imD = cv::imread(string(argv[3]) + "/" + vstrImageFilenamesD[ni], CV_LOAD_IMAGE_UNCHANGED);
```

##### step4 .2. 进行SLAM
`SLAM.TrackRGBD(imRGB, imD, tframe);`
##### step4 .3. 加载下一张图片 

#### step5 . 停止SLAM

## 阅读代码之前你应该知道的事情  

### 变量命名规则  
`ORB-SLAM2`中的变量遵循一套命名规则:  
- 变量名的第一个字母为m表示该变量为某类的成员变量.  
- 变量名的第一、二个字母表示数据类型:  

	- p表示指针类型 
	- n表示int类型  
	- b表示bool类型  
	- s表示std::set类型  
	- v表示std::vector类型  
	- l表示std::list类型  
	- KF表示KeyFrame类型     **关键帧** 

 
 这种将变量类型写进变量名的命名方法叫做*匈牙利命名法*  .

## 多线程
## 1. 同时计算
例如初始化时候同时计算单应矩阵H 和基础矩阵 F 选择重投影误差更小的作为运动估计矩阵。
> 阅读 十四讲 P172

```CPP
// 构造线程来计算H矩阵及其得分
    // thread方法比较特殊，在传递引用的时候，外层需要用ref来进行引用传递，否则就是浅拷贝
    thread threadH(&Initializer::FindHomography,    //该线程的主函数
                   this,                            //由于主函数为类的成员函数，所以第一个参数就应该是当前对象的this指针
                   ref(vbMatchesInliersH),          //输出，特征点对的Inlier标记
                   ref(SH),                         //输出，计算的单应矩阵的RANSAC评分
                   ref(H));                         //输出，计算的单应矩阵结果
    // 计算fundamental matrix并打分，参数定义和H是一样的，这里不再赘述
    thread threadF(&Initializer::FindFundamental,this,ref(vbMatchesInliersF), ref(SF), ref(F));
    // Wait until both threads have finished
    //等待两个计算线程结束
    threadH.join();
    threadF.join();
```

开两个线程同时计算两个矩阵,在多核处理器上会加快运算速度.
## 2. 系统的随机性 (关键帧的产生具有随机性)
因为系统的随机性, 各步骤的运行顺序是不确定的. `Tracking` 线程不产生**关键帧**时, `LocalMapping` 和  `LoopClosing` 线程基本上处于空转的状态. 而`Tracking`线程产生关键帧的频率和时机不是固定的, 因此需要3个线程同时运行, `LocalMapping`和`LoopClosing`线程不断循环查询Tracking线程是否产生关键帧, 产生了的话就处理.
![[ORB--SLAM2.png]]

### 多线程中的锁  
为防止多个线程同时操作同一变量造成混乱,引入锁机制:  
将成员函数本身设为私有变量(`private`或`protected`),并在操作它们的公有函数内加锁.
```CPP
class KeyFrame {
protected:
	KeyFrame* mpParent;
public:
	void KeyFrame::ChangeParent(KeyFrame *pKF) {
		unique_lock<mutex> lockCon(mMutexConnections); // 加锁
		mpParent = pKF;
		pKF->AddChild(this);
	}
	KeyFrame *KeyFrame::GetParent() {
		unique_lock<mutex> lockCon(mMutexConnections); // 加锁
		return mpParent;
	}
}
```

一把锁在某个时刻只有一个线程能够拿到,如果程序执行到某个需要锁的位置,但是锁被别的线程拿着不释放的话,当前线程就会暂停下来;直到其它线程释放了这个锁,当前线程才能拿走锁并继续向下执行.  
 - 什么时候加锁和释放锁? `unique_lock<mutex> lockCon (mMutexConnections);` 这句话就是加锁, 锁的有效性仅限于大括号{}*作用域*之内, 也就是说, 程序运行出大括号之后就自动释放锁了. 因此可以看到有一些代码中加上了看似莫名其妙的大括号.




## SLAM主类System  
`System`类是ORB-SLAM2系统的主类,先分析其主要的成员函数和成员变量:  

[ORB-SLAM2笔记01\_ORB-SLAM2代码运行流程 · 语雀](https://www.yuque.com/chenhai-7zi1m/se4n14/udvggt?inner=11ad2193)

### 构造函数  
`System(const string &strVocFile, string &strSettingsFile, const eSensor sensor, const bool bUseViewer=true)`

```CPP
// step1. 初始化各成员变量
// step1.1. 读取配置文件信息
cv::FileStorage fsSettings(strSettingsFile.c_str(), cv::FileStorage::READ);
// step1.2. 创建ORB词袋
mpVocabulary = new ORBVocabulary();
// step1.3. 创建关键帧数据库,主要保存ORB描述子倒排索引(即根据描述子查找拥有该描述子的关键帧)
mpKeyFrameDatabase = new KeyFrameDatabase(*mpVocabulary);
// step1.4. 创建地图
mpMap = new Map();
// step2. 创建3大线程: Tracking、LocalMapping和LoopClosing
// step2.1. 主线程就是Tracking线程,只需创建Tracking对象即可
mpTracker = new Tracking(this, mpVocabulary, mpFrameDrawer, mpMapDrawer, mpMap, mpKeyFrameDatabase, strSettingsFile, mSensor);
// step2.2. 创建LocalMapping线程及mpLocalMapper
mpLocalMapper = new LocalMapping(mpMap, mSensor==MONOCULAR);
mptLocalMapping = new thread(&ORB_SLAM2::LocalMapping::Run, mpLocalMapper);
// step2.3. 创建LoopClosing线程及mpLoopCloser
mpLoopCloser = new LoopClosing(mpMap, mpKeyFrameDatabase, mpVocabulary, mSensor!=MONOCULAR);
mptLoopClosing = new thread(&ORB_SLAM2::LoopClosing::Run, mpLoopCloser);
// step3. 设置线程间通信
 //设置线程间的通信  关键帧等待队列
mpTracker->SetLocalMapper(mpLocalMapper);
mpTracker->SetLoopClosing(mpLoopCloser);
mpLocalMapper->SetTracker(mpTracker);
mpLocalMapper->SetLoopCloser(mpLoopCloser);
mpLoopCloser->SetTracker(mpTracker);
mpLoopCloser->SetLocalMapper(mpLocalMapper);
```
>`LocalMapping`和`LoopClosing`线程在`System`类中有对应的`std::thread`线程成员变量,为什么`Tracking`线程没有对应的`std::thread`成员变量?  
>因为`Tracking`线程就是主线程,而`LocalMapping`和`LoopClosing`线程是其子线程,主线程通过持有两个子线程的指针(`mptLocalMapping`和`mptLoopClosing`)控制子线程.  
>(ps:虽然在编程实现上三大主要线程构成父子关系,但逻辑上我们认为这三者是并发的,不存在谁控制谁的问题).


### 跟踪函数  
System对象所在的主线程就是跟踪线程,针对不同的传感器类型有3个用于跟踪的函数,其内部实现就是调用成员变量`mpTracker`的`GrabImageMonocular(GrabImageStereo或GrabImageRGBD)`方法.  

| 传感器类型     | 用于跟踪的成员函数                                                                                     |
| --------- | --------------------------------------------------------------------------------------------- |
| MONOCULAR | `cv::Mat TrackRGBD(const cv::Mat &im, const cv::Mat &depthmap, const double &timestamp)`      |
| STEREO    | `cv::Mat TrackStereo(const cv::Mat &imLeft, const cv::Mat &imRight, const double &timestamp)` |
| RGBD      | `cv::Mat TrackMonocular(const cv::Mat &im, const double &timestamp)`                          |
```CPP
cv::Mat System::TrackMonocular(const cv::Mat &im, const double &timestamp) {
cv::Mat Tcw = mpTracker->GrabImageMonocular(im, timestamp);
unique_lock<mutex> lock(mMutexState);
mTrackingState = mpTracker->mState;
mTrackedMapPoints = mpTracker->mCurrentFrame.mvpMapPoints;
mTrackedKeyPointsUn = mpTracker->mCurrentFrame.mvKeysUn;
return Tcw;
}
```